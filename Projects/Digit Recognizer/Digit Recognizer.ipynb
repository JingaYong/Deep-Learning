{
 "cells": [
  {
   "cell_type": "raw",
   "id": "196d2f6f-d8f0-41d6-a8d4-6259bdc21bff",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be56b564-7667-4577-9424-5f9796a5299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, LSTM, Conv2D, Flatten, Rescaling, MaxPooling2D, BatchNormalization,ReLU\n",
    "from sklearn.model_selection import train_test_split as tt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0b14f22-82b1-49b5-b5d3-3a11f18ea407",
   "metadata": {},
   "source": [
    "Reading csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae05e36d-9431-42c3-80d5-588074e8a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(\"train.csv\")\n",
    "# df_test = pd.read_csv(\"test.csv\")\n",
    "# df_sub = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7cc5eca-e962-4fc4-9f1e-295d305ac3e0",
   "metadata": {},
   "source": [
    "Splitting dat into features and labels, further dividing them into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2683e-1e43-47b3-8d0d-5184288ba932",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(df_train.drop('label',axis=1))\n",
    "y = df_train['label']\n",
    "\n",
    "x_train,x_val,y_train,y_val = tt(x,y,train_size=0.8,random_state=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b064048-060a-456f-8050-f3efa10a3a31",
   "metadata": {},
   "source": [
    "Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b7be2-5d00-4cf6-8a71-758cefe1d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28,1).astype(\"float32\") / 255.0\n",
    "x_val = x_val.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "928f9f17-5bad-47b0-8ad2-18e585ad6ce1",
   "metadata": {},
   "source": [
    "CNN model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468825c-efa6-4d0d-b99e-ddd3015b37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  tf.keras.Input(shape=(28,28,1)),\n",
    "  Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  MaxPooling2D(),\n",
    "  Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  MaxPooling2D(),\n",
    "  Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  MaxPooling2D(),\n",
    "  Flatten(),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.003),metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad38632f-42c0-4c6a-aa37-b31a7e096033",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90613a5-9684-4cac-8a7d-efcea638006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "history = model.fit(x_train,y_train,batch_size=64,epochs=epochs,validation_data=(x_val, y_val),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4f27d-a34c-4da0-9238-2a6f20df1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualizing the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854c7b7-3e39-42b6-b46f-41f3cd71f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c256dd4-7d5d-47ea-9ef4-3d6182be930d",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261c72c-9a53-470a-9111-5ab973509567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"digits_recogniser_model.h5\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb347353-35de-4ecc-89bb-cfbdab07d0be",
   "metadata": {},
   "source": [
    "Loading the model and predicting the output for given inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01fa5ef-1bba-4a99-b68d-187594f9d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('../cnn_py_files/digits_recogniser_model.h5')\n",
    "# # Test Data\n",
    "# x_test = np.asarray(df_test)\n",
    "# x_test = x_test.astype(\"float32\") / 255.0\n",
    "# print(x_test[0].shape)\n",
    "# def predictions():\n",
    "#     preds = []\n",
    "#     for i in range(x_test.shape[0]):\n",
    "#         ip = x_test[i].reshape(-1, 28, 28, 1)\n",
    "#         pred = model.predict(ip)\n",
    "#         # print(pred)\n",
    "#         # # Softmax - func\n",
    "#         p = np.exp(pred)\n",
    "#         s = p / p.sum()\n",
    "#         preds.append(np.argmax(s))\n",
    "#     return preds\n",
    "#\n",
    "# op = predictions()\n",
    "# print(op)\n",
    "#\n",
    "#\n",
    "# with open('op_file', 'wb') as f:\n",
    "#     pickle.dump(op, f)\n",
    "\n",
    "\n",
    "with open('op_file', 'rb') as fp:\n",
    "    output = pickle.load(fp)\n",
    "\n",
    "output = list(output)\n",
    "index = list(df_sub.ImageId)\n",
    "# print(index)\n",
    "# output = np.asarray(output).reshape((-1,1))\n",
    "# index = np.asarray(df_sub.ImageId).reshape((-1,1))\n",
    "# print(output.shape)\n",
    "# print(len(output))\n",
    "new_df = pd.DataFrame({'ImageId':index,'Predicted_Label':output})\n",
    "# new_df = new_df.set_index('ImageId')\n",
    "print(new_df.head())\n",
    "\n",
    "# Save to csv\n",
    "new_df.to_csv('prediction_submission.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
